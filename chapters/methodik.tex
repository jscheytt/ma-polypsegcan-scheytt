\chapter{Material und Methoden -- 40~\%}

\section{Conditional Adversarial Networks}

\subsection{Generative Adversarial Networks}

Die Auflösung der originalen \glspl{gan} war noch nicht sehr hoch.
LAPGANs verbessern diese, indem ein Generator pro Upsampling-Stufe zum Einsatz kommt, der eine Verfeinerung eines Gauss'schen Upsamplings lernt wie in einer Laplace'schen Pyramide.
\glspl{dcgan} erzeugen eine noch bessere Qualität, indem statt gelegentlichen Pooling-Operationen nur noch Faltungsschichten zum Einsatz kommen.
Zusätzlich wird auch noch Batch Normalization genutzt.

Diese \glspl{dcgan} kommen bei den \glspl{can} im Generator-Netz zum Einsatz.

\subsection{U-Net}

\glspl{fcn} sind die erste Variante von tiefen Netzen, die Segmentierungen produzieren kann.
Sie sind in ihrem Aufbau den Autoencodern sehr ähnlich, allerdings haben sie Zwischenverbindungen, sogenannte "Skip Connections", zwischen gegenüberliegenden Schichten jeder Skalierungsstufe.

Das U-Net ist eine Erweiterung, die sich folgendermaßen von den \glspl{fcn} abgrenzt:
[]

Diese Architektur wird ebenfalls im Generator des \gls{can} genutzt.

\section{Regularisierung}

Im Originalpaper der \glspl{can} wurde gezeigt, dass eine Image-to-Image-Translation mit dem Ziel der semantischen Segmentierung zwar möglich ist, aber teilweise zu stark zu Overfitting tendiert:
Oftmals produzierte das Netz viele kleine Segmentierungs-Regionen und zeigte damit, dass es viele kleine Objekte in die Szene hinein "halluzinierte", die in Realität nicht vorhanden waren.

In dieser Arbeit möchte ich u.~a. untersuchen, wie sich die \glspl{can} bei einer binären semantischen Segmentierung verhalten, wenn man verschiedene Strategien der Regularisierung anwendet.
[Definition Regularisierung]

Eine Regularisierungsstrategie, die sich vor allem bei Bildmaterial sehr gut eignet, ist ein künstliches Vergrößern des Datasets, die sogenannte "Dataset Augmentation".
[Erklärung Dataset Augmentation]

Im vorliegenden Szenario bieten sich folgende Techniken der Dataset Augmentation besonders an:
[Augmentation Strategie Polypen-FCNs übernehmen, zitieren, erläutern warum das gut bei Polypen passt (und warum andere Techniken wahrscheinlich nicht so gut dafür sind)]

Es existieren einige weitere Regularisierungsstrategien für tiefe Netze \cite{Goodfellow.2016}:
[aufzählen, auf jede einzelne eingehen (z. B. Batchnormalisierung wird auch massiv in DCGANs eingesetzt)]

Eine Anpassung der Verlustfunktion durch Bestrafungsterme erscheint als die einzige Möglichkeit, die Halluzination kleiner Objekte einzudämmen.
Dies würde allerdings eine der Hauptentdeckungen der \glspl{can} zunichte machen, nämlich dass nicht einmal mehr die Verlustfunktion von Hand erstellt werden muss, sondern vom Netz gelernt werden kann.

\section{Form aus Sequenzbetrachtung}

Aus dem Stand der Technik und der Analyse von Koloskopie-Bildmaterial ergibt sich, dass neben sekundären Merkmalen wie Farbe und Textur die Form das aussagekräftigste Merkmal ist.
Aussagen über die Form würden wir am direktesten über die Tiefeninformation bekommen, aber wir haben oftmals nur monokulare Aufnahmen und damit keine unmittelbaren Tiefendaten vorliegen.
In der klassischen Bildverarbeitung ist es aber durch das Erfassen von Punktkorrespondenzen zwischen sequentiell aufgenommenen Bildern möglich, die Tiefeninformation einer Szene ungefähr zu rekonstruieren.
Dieser Bereich der Bildverarbeitung nennt sich "Structure from Motion".

Möglicherweise ist auch ein tiefes Netz dazu in der Lage, Tiefenstrukturen aus der Kamerabewegung abzuleiten.
Dazu muss man ihm allerdings mehrere konsekutive Frames zur Verfügung stellen.
Eine Architektur wie die 3D-FCNs liefert dafür eine gute Grundlage.

\subsection{3D-Faltung}

Den 3D-FCNs von \cite{Lequan.2017} liegen die 3D-CNNs zugrunde, welche zur Verarbeitung von dreidimensionalen Bilddaten genutzt werden können.
\citeauthor{Lequan.2017} nutzen diese allerdings unter der Annahme, dass ein Video auch nur ein 3D-Volumen ist.
Hierbei ist die zeitliche Komponente die dritte Dimension und die Zeitachse ihre Richtung -- es ergibt sich durch Aufeinanderstapeln der sequentiell angeordneten Frames ein 3D-Volumen.

[3D-Faltung erklären]

Bei den \glspl{can} ließe sich eine 3D-Faltung folgendermaßen umsetzen:
[]

\subsection{Optischer Fluss}

Zusätzlich zum 3D-Ansatz wäre auch eine reduzierte Variante mit optischem Fluss denkbar:
Man gibt dem Netz statt einem 3D-Volumen aus konsekutiven Frames einen einzelnen Frame inklusive der Information über den optischen Fluss vom vorherigen Frame zum jetzigen.
Je nach Geschwindigkeit des Tracking des optischen Flusses könnte dies die Gesamtperformanz des Systems theoretisch erhöhen, da maximal zwei Bilder auf einmal verarbeitet werden müssen.

Alle Teilansätze, die auf Seqenzbetrachtung beruhen, um Tiefeninformation zu generieren, sollten im Idealfall auch dann funktionieren, wenn nur ein einziger Input-Frame gegeben wird.

\subsection{Weitere DL-Methoden zur Tiefenschätzung}

\citeauthor{Mahmood.20171129} lassen mithilfe eines Transformer-GAN und Selbstregularisierung eine Transformation von realen zu synthetischen Bildern lernen, sodass dann auf dem synthetischen Bild die Tiefe geschätzt werden kann.
[sieht vielversprechend aus, aber steht uns nicht zur Verfügung]

\section{Dataset}

Im Zuge der MICCAI-Konferenz 2017 wurde auch eine neue Auflage der Endoscopic Vision Challenge ausgerichtet, die schon 2015 viele neue Ansätze in der endoskopischen Bildverarbeitung hervorbrachte.
Auch dieses Mal gab es wieder eine Sub-Challenge zur Polypen-Segmentierung, die Teil der GIANA ist.

[Herkunft der einzelnen Bestandteile des Datasets]

[Quantitative Beschreibung der Komponenten des Datasets]
