\documentclass[12pt]{article}

%%% Packages

\usepackage[utf8]{inputenc}

\usepackage[
	backend=biber,
	minbibnames=3,
	maxbibnames=3,
	giveninits=true,
	eprint=false,
]{biblatex}
\addbibresource{references.bib}
\AtEveryBibitem{
	\clearfield{eventtitle}
	\clearfield{venue}
	\clearlist{organization}
	\clearfield{series}
	\clearlist{editor}
	\clearfield{note}
	\clearfield{booksubtitle}
	\ifentrytype{misc}{}{\clearfield{url}}
}

\usepackage[babel]{csquotes}
\MakeOuterQuote{"}

\usepackage[acronym,automake]{glossaries}
\newacronym{gan}{GAN}{Generative Adversarial Network}
\newacronym{can}{CAN}{Conditional Adversarial Network}
\newacronym{dcgan}{DCGAN}{Deep Convolutional GAN}
\makeglossaries

%%% Title

\title{EndoVis GIANA Challenge 2018 Polyp Segmentation SD -- Binary Segmentation Conditional Adversarial Networks (BSCAN)}
\author{Josia Scheytt\thanks{Reutlingen University}, Cristobal Curio\footnotemark[1], Oliver Burgert\footnotemark[1]}

%%% Content

\begin{document}

\maketitle

\begin{abstract}
Automatically localizing polyps in colonoscopic imagery is a difficult task because polyp appearance varies greatly in color, texture, and shape.
Recently, conditional variants of \glspl{gan} have been developed for a wide range of image-to-image translation tasks.
To our knowledge, we are the first to use this deep learning architecture for segmenting colorectal polyps.
We enhance the original methodology for the binary segmentation task.
\end{abstract}

\glspl{gan}~\cite{Goodfellow.2014} are designed to unsupervisedly learn to generate realistic outputs in terms of closeness to the training data.
Conditioned \glspl{gan} receive an additional input for conditioning the output which makes them useful for supervised learning problems on images.

\citeauthor{Isola.2017} develop \glspl{can}~\cite{Isola.2017} to tackle general mapping of one scene representation to another, e.~g. style transfer, day-to-night, or colorization.
Using an L1 loss for low image frequencies and a patch-based discriminator for high frequencies, the net is able to learn a structured loss solely from the training data with no need for loss engineering.
The architecture is based on \glspl{dcgan}~\cite{Radford.2016} and the generator is a U-Net~\cite{Ronneberger.2015}.
We evaluate \glspl{can} on the GIANA polyp segmentation SD subtask and change the following:

Outputs are limited to 256$\times$256 resolution, so we use \emph{bicubic upsampling at test time} to achieve the desired output resolution.
%TODO maybe insert results of evaluation
The generated outputs are 3-channel images but very close to binary images, so we simply \emph{average all channels and threshold} them by half the maximum value.
Training can easily be subject to vanishing gradients, so we determine the minimum batch size (3) and \emph{best batch size} (32, used for final results) as a compromise between learning stability and limited memory.
Dropout is applied both at training and test time to generate rich and naturalistic outputs but binary segmentation results vary too much, so we \emph{deactivate dropout at test time}.
Furthermore we evaluate the use of dataset augmentation by using the same techniques as \citeauthor{Vazquez.2017}~\cite{Vazquez.2017}: zooming, rotation, and shearing.
%TODO insert results of evaluation

\printbibliography

\end{document}
